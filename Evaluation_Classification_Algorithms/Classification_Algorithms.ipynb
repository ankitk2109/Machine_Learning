{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Bias- Core Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "bcDB = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcDF = pd.DataFrame(bcDB.data, columns= list(bcDB['feature_names']))\n",
    "bcDF['target'] = pd.Series(bcDB.target)\n",
    "bcDF = bcDF.sort_values(by = ['target'])\n",
    "bcDF = bcDF.reset_index(drop=True)\n",
    "bcDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = bcDF['target'].value_counts()\n",
    "for i,j in enumerate(bcDB.target_names):\n",
    "    print (vc[i],j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bcDF.pop('target').values\n",
    "X = bcDF.values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for creating Confusion Matrix and Printing False Positive(FP) Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Oranges):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    fp_rate = cm[0,1]/(cm[0,1]+cm[0,0])\n",
    "    print('FP Rate is:', fp_rate)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"black\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-Out Method\n",
    "\n",
    "### In Hold-out stratergy we keep some training data back (the hold-out set) to use for evaluating the model produced by the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hold Out\n",
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "print (\"Accuracy Score: \", accuracy_score(y_test,y_pred))\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier(criterion='entropy')\n",
    "dt_tree = DT.fit(X_train,y_train)\n",
    "y_pred = dt_tree.predict(X_test)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "print (\"Accuracy Score: \", accuracy_score(y_test,y_pred))\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "bc_NB = gnb.fit(X_train,y_train)\n",
    "y_test= bc_NB.predict(X_test)\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "print (\"Accuracy Score: \", accuracy_score(y_test,y_pred))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg=LogisticRegression()\n",
    "y_pred=logReg.fit(X_train,y_train).predict(X_test)\n",
    "y_test.sum()/len(y_test)\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "print (\"Accuracy Score: \", accuracy_score(y_test,y_pred))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Method\n",
    "\n",
    "### Cross-validation or ‘k-fold cross-validation’ is when the dataset is randomly split up into ‘k’ groups. One of the groups is used as the test set and the rest are used as the training set. The model is trained on the training set and scored on the test set. Then the process is repeated until each unique group as been used as the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_scores = cross_val_score(kNN, X, y, cv=10, scoring='f1')\n",
    "print(\"10x CV Accuracy kNNs: {0:.2f}\".format(kNN_scores.mean())) \n",
    "y_pred = cross_val_predict(kNN, X, y, cv=10)\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y.sum()/len(y))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "fpr_knn, tpr_knn, t_knn = roc_curve(y, y_pred)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_scores = cross_val_score(DT, X, y, cv=10, scoring='f1')\n",
    "print(\"10x CV Accuracy Trees: {0:.2f}\".format(tree_scores.mean())) \n",
    "y_pred = cross_val_predict(DT, X, y, cv=10)\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y.sum()/len(y))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "fpr_dt, tpr_dt, t_dt = roc_curve(y, y_pred)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_scores = cross_val_score(gnb, X, y, cv=10,scoring='f1')\n",
    "print(\"10x CV Accuracy Naive: {0:.2f}\".format(gnb_scores.mean())) \n",
    "y_pred = cross_val_predict(gnb, X, y, cv=10)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y.sum()/len(y))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "#y_pred = gnb.fit(X_train, y_train).predict_proba(y.rehsape(1,-1))\n",
    "fpr_gnb, tpr_gnb, t_gnb = roc_curve(y, y_pred)\n",
    "roc_auc_gnb = auc(fpr_gnb, tpr_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_scores = cross_val_score(logReg, X, y, cv=10,scoring='f1')\n",
    "print(\"10x CV Accuracy Logistic Regression: {0:.2f}\".format(logReg_scores.mean())) \n",
    "y_pred = cross_val_predict(logReg, X, y, cv=10)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y.sum()/len(y))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "fpr_lr, tpr_lr, t_lr = roc_curve(y, y_pred)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP & TP Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "scoring = {'tp' : make_scorer(tp), 'tn' : make_scorer(tn),\n",
    "           'fp' : make_scorer(fp), 'fn' : make_scorer(fn)}\n",
    "\n",
    "print(tp)\n",
    "models = [kNN,DT,gnb,logReg]\n",
    "\n",
    "folds = 4\n",
    "v = 0 #  use 1 or 0\n",
    "\n",
    "for m in models:\n",
    "    cv_results = cross_validate(m, X, y, cv= folds,scoring=scoring, return_train_score=False, \n",
    "                                    verbose = v, n_jobs = -1)\n",
    "    fp_rate = cv_results['test_fp'].sum()/(cv_results['test_fp'].sum()+cv_results['test_tn'].sum())\n",
    "    tp_rate = cv_results['test_tp'].sum()/(cv_results['test_tp'].sum()+cv_results['test_fn'].sum())\n",
    "  \n",
    "    print(\"{} x CV {:22} FP: {:.2f}  TP: {:.2f}\".format(folds, type(m).__name__, fp_rate, tp_rate)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### Looking at the results of both the methods for all  algorithms, it can be seen that cross validation performs better with high accuracy rates. However, it can be seen that malignant is a minority class but still our predicted values are less then the actual test values showing that these algorithms are biased over majority class. \n",
    "\n",
    "### Also over all the algorithms FP rate for kNN is highest. Hence kNN is the most biased among these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoC curve ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize = (18,9), dpi=250)\n",
    "lw = 7\n",
    "plt.plot(fpr_knn, tpr_knn, color='red',\n",
    "         lw=lw, label='ROC kNN (area = %0.2f)' % roc_auc_knn)\n",
    "\n",
    "plt.plot(fpr_dt, tpr_dt, color='green',\n",
    "         lw=lw, label='ROC DecisionTree (area = %0.2f)' % roc_auc_dt)\n",
    "\n",
    "plt.plot(fpr_gnb, tpr_gnb, color='blue',\n",
    "         lw=lw, label='ROC GaussianNB (area = %0.2f)' % roc_auc_gnb)\n",
    "\n",
    "plt.plot(fpr_lr, tpr_lr, color='orange',\n",
    "         lw=lw, label='ROC LogisticRegression (area = %0.2f)' % roc_auc_lr)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate', fontsize=20)\n",
    "plt.ylabel('True Positive Rate', fontsize=20)\n",
    "plt.title('ROC Analysis for Hotel Review data', fontsize=25)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Oversampling stratergy for Imbalance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance Dataset: When the distribution of classes present in a data is not uniform such that the number of instances of a class significantly out numbers the instances of another class leads to class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To recifying the bias there are several methods available, but I have used Random Oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ran_ovr_samp = RandomOverSampler(random_state = 0)\n",
    "X_newsample, y_newsample = ran_ovr_samp.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_newsample, y_newsample, random_state = 2 , stratify = y_newsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "#print(X_train.shape,X_test.shape)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DT.fit(X_train, y_train).predict(X_test)\n",
    "#print(X_train.shape,X_test.shape)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "#print(X_train.shape,X_test.shape)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logReg.fit(X_train, y_train).predict(X_test)\n",
    "#print(X_train.shape,X_test.shape)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Malignant','Benign'], normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP rates of each Algorithms:\n",
    "##### kNN : 0.0888\n",
    "##### Decision Tree: 0.0333\n",
    "##### Gaussian Naive Bayes: 0.0777\n",
    "##### Logarithmic Regression: 0.0222\n",
    "\n",
    "#### Random Oversampling: This method works with minority class. It replicates the observations from minority class to balance the data. It randomly oversampling the minority class. An advantage of using this method is that it leads to no information loss\n",
    "#### After applying random oversampling  the FP rates significantly decreases for each algorithm implying that algorithms are now less biased.The disadvantage of using this method is that, since oversampling simply adds replicated observations in original data set, it ends up adding multiple observations of several types, thus leading to overfitting. Although, the training accuracy of such data set will be high, but the accuracy on unseen data will be worse.\n",
    "\n",
    "#### Based on the results the FP rate of Logarithmic Regression least hence performing best in my case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Algorithm on Cryotherapy Dataset\n",
    "\n",
    "#### Crytherapy Dataset: This dataset is used to classify whether the person was treated successfully or not based on six features age,sex,time,Number_of_Warts,type and area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = r\"D:\\Study\\ML_Python\\Assignment\\divorce\\Cryotherapy.xlsx\"\n",
    "cryo_df= pd.read_excel(path)\n",
    "cryo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryo_yes = cryo_df['Result_of_Treatment'].sum()\n",
    "cryo_no  = len(cryo_df['Result_of_Treatment']) - cryo_df['Result_of_Treatment'].sum()\n",
    "print ('Result Yes: ', cryo_yes)\n",
    "print ('Result No: ',cryo_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cryo_df.pop('Result_of_Treatment').values\n",
    "X = cryo_df.values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have applied both hold-out and Oversampling method on this dataset to which works better because the dataset is imbalance as it has more number of patients that are not treated correctly vs patients that were treated correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3)\n",
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Disease treated successfully in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted treated disease : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "print (\"Accuracy Score: \", accuracy_score(y_test,y_pred))\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Disease Treated','Disease Not Treated'], normalize=False,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion='entropy')\n",
    "y_pred = DT.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Disease treated successfully in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted treated disease : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "print (\"Accuracy Score: \", accuracy_score(y_test,y_pred))\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Disease Treated','Disease Not Treated'], normalize=False,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Disease treated successfully in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted treated disease : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "print (\"Accuracy Score: \", accuracy_score(y_test,y_pred))\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Disease Treated','Disease Not Treated'], normalize=False,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg=LogisticRegression()\n",
    "y_pred = logReg.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Disease treated successfully in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted treated disease : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Disease Treated','Disease Not Treated'], normalize=False,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OverSampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_ovr_samp = RandomOverSampler(random_state = 4)\n",
    "X_newsample, y_newsample = ran_ovr_samp.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_newsample, y_newsample, random_state=2)\n",
    "y_pred = kNN.fit(X_train, y_train).predict(X_test)\n",
    "#print(X_train.shape,X_test.shape)\n",
    "\n",
    "print(\"Disease treated successfully in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted treated disease : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Disease Treated','Disease Not Treated'], normalize=False,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_ovr_samp = RandomOverSampler(random_state = 4)\n",
    "X_newsample, y_newsample = ran_ovr_samp.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_newsample, y_newsample, random_state=1)\n",
    "y_pred = DT.fit(X_train, y_train).predict(X_test)\n",
    "#print(X_train.shape,X_test.shape)\n",
    "\n",
    "print(\"Disease treated successfully in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted treated disease : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Disease Treated','Disease Not Treated'], normalize=False,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_ovr_samp = RandomOverSampler(random_state = 2)\n",
    "X_newsample, y_newsample = ran_ovr_samp.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_newsample, y_newsample, random_state=9)\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "#print(X_train.shape,X_test.shape)\n",
    "\n",
    "print(\"Malignant in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted malignant : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Disease Treated','Disease Not Treated'], normalize=False,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_ovr_samp = RandomOverSampler(random_state = 3)\n",
    "X_newsample, y_newsample = ran_ovr_samp.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_newsample, y_newsample, random_state=0)\n",
    "logReg=LogisticRegression()\n",
    "y_pred = logReg.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Disease treated successfully in test set : %0.2f\" % (1- (y_test.sum()/len(y_test))))\n",
    "print(\"Predicted treated disease : %0.2f\" % (1- (y_pred.sum()/len(y_pred))))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=['Disease Treated','Disease Not Treated'], normalize=False,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP-Rate for each algorithms\n",
    "\n",
    "#### kNN,Decison Tree,Gaussian naive Bayes,Logistic Regression\n",
    "#### 0.3243,0.324,0.486,0.21 : Hand-Out\t\n",
    "#### 0.28,024,0.36,0.16: Oversampling\n",
    "\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "#### As the dataset was imbalanced the intial hand-out algorithms were biased. After applying oversampling it can be seen above that the FP rate decreases for each classification alorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
